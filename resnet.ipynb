{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import torch\n",
    "# # model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "# # # or any of these variants\n",
    "# # # model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
    "# # # model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "# # # model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
    "# # # model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n",
    "# # model.eval()\n",
    "\n",
    "# from PIL import Image\n",
    "# from torchvision import transforms\n",
    "\n",
    "# filename = 'dog.jpg'\n",
    "\n",
    "# input_image = Image.open(filename)\n",
    "# preprocess = transforms.Compose([\n",
    "#     transforms.Resize(256),\n",
    "#     transforms.CenterCrop(224),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "# ])\n",
    "# input_tensor = preprocess(input_image)\n",
    "# input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "# # move the input and model to GPU for speed if available\n",
    "# if torch.cuda.is_available():\n",
    "#     input_batch = input_batch.to('cuda')\n",
    "#     model.to('cuda')\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     output = model(input_batch)\n",
    "# # Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
    "# # print(output[0])\n",
    "# # The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "# probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "# # print(probabilities)\n",
    "\n",
    "# # Read the categories\n",
    "# with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "#     categories = [s.strip() for s in f.readlines()]\n",
    "# # Show top categories per image\n",
    "# top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "# for i in range(top5_prob.size(0)):\n",
    "#     print(categories[top5_catid[i]], top5_prob[i].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "learning_rate = 1e-3 #@param\n",
    "batch_size = 64 #@param\n",
    "epochs = 2000 #@param\n",
    "\n",
    "NUM_CLASSES = 22\n",
    "LABELS = [\n",
    "    \"ape\", \"bear\", \"bison\", \"cat\",\n",
    "    \"chicken\", \"cow\", \"deer\", \"dog\",\n",
    "    \"dolphin\", \"duck\", \"eagle\", \"fish\",\n",
    "    \"horse\", \"lion\", \"lobster\", \"pig\",\n",
    "    \"rabbit\", \"shark\", \"snake\", \"spider\",\n",
    "    \"turkey\", \"wolf\"\n",
    "]\n",
    "LABEL_MAP = {\n",
    "    0: \"ape\", 1: \"bear\", 2: \"bison\", 3: \"cat\",\n",
    "    4: \"chicken\", 5: \"cow\", 6: \"deer\", 7: \"dog\",\n",
    "    8: \"dolphin\", 9: \"duck\", 10: \"eagle\", 11: \"fish\",\n",
    "    12: \"horse\", 13: \"lion\", 14: \"lobster\",\n",
    "    15: \"pig\", 16: \"rabbit\", 17: \"shark\", 18: \"snake\",\n",
    "    19: \"spider\", 20:  \"turkey\", 21: \"wolf\"\n",
    "}\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.datasets import VisionDataset\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "\n",
    "class TEST(VisionDataset):\n",
    "    def __init__(self,root, transform, target_transform):\n",
    "        self.img_dir = root\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.samples = os.listdir(self.img_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.normpath(os.path.join(self.img_dir, self.samples[index]))\n",
    "        with open(img_path, \"rb\") as f:\n",
    "            img = Image.open(f).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "from torchvision.datasets import ImageFolder, VisionDataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "data_path = 'Animals/Animals_Dataset' #@param\n",
    "batch_size = 16 #@param\n",
    "num_workers = 2 #@param\n",
    "\n",
    "train_path = os.path.normpath((os.path.join(data_path, 'train')))\n",
    "test_path = os.path.normpath((os.path.join(data_path, 'test')))\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "label2onehot = transforms.Lambda(lambda y: torch.zeros(\n",
    "    NUM_CLASSES, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))\n",
    "\n",
    "train_dataset = ImageFolder(\n",
    "    train_path,\n",
    "    preprocess,\n",
    "    target_transform = label2onehot\n",
    ")\n",
    "test_dataset = TEST(\n",
    "    test_path,\n",
    "    transform = preprocess,\n",
    "    target_transform = label2onehot \n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers) #!TODO: rewrite this statement\n",
    "model = models.resnet18(weights = torchvision.models.ResNet18_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "fc_infeatures = model.fc.in_features\n",
    "model.fc = nn.Linear(fc_infeatures, NUM_CLASSES)\n",
    "model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "  \"\"\"Computes and stores the average and current value\"\"\"\n",
    "  def __init__(self, name, fmt=':f'):\n",
    "      self.name = name\n",
    "      self.fmt = fmt\n",
    "      self.reset()\n",
    "\n",
    "  def reset(self):\n",
    "      self.val = 0\n",
    "      self.avg = 0\n",
    "      self.sum = 0\n",
    "      self.count = 0\n",
    "\n",
    "  def update(self, val, n=1):\n",
    "      self.val = val\n",
    "      self.sum += val * n\n",
    "      self.count += n\n",
    "      self.avg = self.sum / self.count\n",
    "\n",
    "  def __str__(self):\n",
    "      fmtstr = '{name} {avg' + self.fmt + '}'\n",
    "      return fmtstr.format(**self.__dict__)\n",
    "\n",
    "def accuracy(output:torch.Tensor, target, topk=(1,)):\n",
    "  \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "  with torch.no_grad():\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    print(pred.shape, target.shape)\n",
    "    pred = pred.t()\n",
    "    print(target.view(1, -1).shape)\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "batch_time = AverageMeter('Time', ':6.3f')\n",
    "data_time = AverageMeter('Data', ':6.3f')\n",
    "losses = AverageMeter('Loss', ':.4e')\n",
    "top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "top5 = AverageMeter('Acc@5', ':6.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_params_id = list(map(id, model.fc.parameters()))     \n",
    "base_params = filter(lambda p: id(p) not in fc_params_id, model.parameters())\n",
    "optimizer = torch.optim.SGD([\n",
    "    {'params': base_params, 'lr': learning_rate*0},   #冻结卷积层的方法，\n",
    "    {'params': model.fc.parameters(), 'lr': learning_rate}], momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <function <lambda> at 0x000001BABD1FB560>: attribute lookup <lambda> on __main__ failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\15135\\Desktop\\AI_Front\\resnet.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell://ssh-remote%2B769p17k135.yicp.fun/c%3A/Users/15135/Desktop/AI_Front/resnet.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m      <a href='vscode-notebook-cell://ssh-remote%2B769p17k135.yicp.fun/c%3A/Users/15135/Desktop/AI_Front/resnet.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m----> <a href='vscode-notebook-cell://ssh-remote%2B769p17k135.yicp.fun/c%3A/Users/15135/Desktop/AI_Front/resnet.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m   \u001b[39mfor\u001b[39;00m batch, (X, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39;49m(train_loader):\n\u001b[0;32m      <a href='vscode-notebook-cell://ssh-remote%2B769p17k135.yicp.fun/c%3A/Users/15135/Desktop/AI_Front/resnet.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      <a href='vscode-notebook-cell://ssh-remote%2B769p17k135.yicp.fun/c%3A/Users/15135/Desktop/AI_Front/resnet.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ai_front\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:441\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    440\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ai_front\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ai_front\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1042\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1035\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1043\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ai_front\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ai_front\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ai_front\\Lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ai_front\\Lib\\multiprocessing\\popen_spawn_win32.py:94\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 94\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     95\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     96\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ai_front\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <function <lambda> at 0x000001BABD1FB560>: attribute lookup <lambda> on __main__ failed"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "for i in range(epochs):\n",
    "  for batch, (X, y) in enumerate(train_loader):\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "    data_time.update(time.time() - start)\n",
    "    pred = model(X)\n",
    "    loss = loss_fn(pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # acc1, acc5 = accuracy(pred, y, topk=(1, 5))\n",
    "    losses.update(loss.item(), X.size(0))\n",
    "    # top1.update(acc1[0], X.size(0))\n",
    "    # top5.update(acc5[0], X.size(0))\n",
    "\n",
    "  batch_time.update(time.time() - start)\n",
    "  start = time.time()\n",
    "\n",
    "  print(f\"Epoch:{i + 1}: {batch_time}, {losses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'resnet.path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('resnet.path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "  for _, images in enumerate(test_loader):\n",
    "    y = model(images.to(device))\n",
    "    batch_labels = torch.argmax(y, dim=1)\n",
    "    labels.append(batch_labels)\n",
    "ans = torch.cat(labels, 0).cpu().numpy()\n",
    "print(ans)\n",
    "print([LABEL_MAP[i] for i in ans])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_front",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
